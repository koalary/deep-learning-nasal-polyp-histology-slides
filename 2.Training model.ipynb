{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Lambda\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = '/mnt/dgx1/koalary/train/' \n",
    "test_image_path = '/mnt/dgx1/koalary/internal-validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "import os\n",
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['controlled']:\n",
    "                label = 0\n",
    "            elif nextDir in ['uncontrolled']:\n",
    "                label = 1\n",
    "                \n",
    "            temp = Dir + nextDir\n",
    "                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                image = load_img(temp + '/' + file,target_size=(256,256))\n",
    "                image = img_to_array(image)\n",
    "                image /= 255\n",
    "                X.append(image)\n",
    "                y.append(label)\n",
    "                image_list.append(file)   \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = get_data(train_image_path)\n",
    "x_test,y_test = get_data(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_train = to_categorical(y_train, 2)\n",
    "Y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn \n",
    "efnmodel = efn.EfficientNetB5(include_top=True, weights=None, input_tensor=None, input_shape=(256,256,3)) \n",
    "efnmodel.load_weights('./weights/efficientnet-b5_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "x = efnmodel.layers[-2].output\n",
    "output_layer = Dense(2, activation='softmax', name='fc2')(x)\n",
    "\n",
    "# combine the original model with the new output layer\n",
    "efn2 = Model(inputs=efnmodel.input, outputs=output_layer)\n",
    "\n",
    "# compile the new model\n",
    "efn2.compile(optimizer=Adam(lr=0.0001), # lr=0.0001\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath = 'efficientnet_0.0001.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = efn2.fit(x_train, Y_train, \n",
    "                 batch_size=32, \n",
    "                 epochs=100, \n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint],\n",
    "                 validation_data = (x_test , Y_test),\n",
    "                 shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn \n",
    "efnmodel = efn.EfficientNetB5(include_top=True, weights=None, input_tensor=None, input_shape=(256,256,3)) \n",
    "efnmodel.load_weights('./weights/efficientnet-b5_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "x = efnmodel.layers[-2].output\n",
    "output_layer = Dense(2, activation='softmax', name='fc2')(x)\n",
    "\n",
    "# combine the original model with the new output layer\n",
    "efn2 = Model(inputs=efnmodel.input, outputs=output_layer)\n",
    "\n",
    "# compile the new model\n",
    "efn2.compile(optimizer=Adam(lr=0.001), # lr=0.001\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath = 'efficientnet_0.001.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = efn2.fit(x_train, Y_train, \n",
    "                 batch_size=32, \n",
    "                 epochs=100, \n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint],\n",
    "                 validation_data = (x_test , Y_test),\n",
    "                 shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn \n",
    "efnmodel = efn.EfficientNetB5(include_top=True, weights=None, input_tensor=None, input_shape=(256,256,3)) \n",
    "efnmodel.load_weights('./weights/efficientnet-b5_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "x = efnmodel.layers[-2].output\n",
    "output_layer = Dense(2, activation='softmax', name='fc2')(x)\n",
    "\n",
    "# combine the original model with the new output layer\n",
    "efn2 = Model(inputs=efnmodel.input, outputs=output_layer)\n",
    "\n",
    "# compile the new model\n",
    "efn2.compile(optimizer=Adam(lr=0.0008), # lr=0.0008\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath = 'efficientnet_0.0008.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = efn2.fit(x_train, Y_train, \n",
    "                 batch_size=32, \n",
    "                 epochs=100, \n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint],\n",
    "                 validation_data = (x_test , Y_test),\n",
    "                 shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV3 = InceptionV3(include_top=True, weights=None,\n",
    "                               input_tensor=None, input_shape=(256,256,3), pooling=None)\n",
    "\n",
    "IV3.load_weights('./weights/inception_v3_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "# define a new output layer to connect with the last fc layer\n",
    "x = IV3.layers[-2].output\n",
    "output_layer = Dense(2, activation='softmax', name='fc2')(x)\n",
    "\n",
    "# combine the original model with the new output layer\n",
    "IV3_2 = Model(inputs=IV3.input, outputs=output_layer)\n",
    "\n",
    "# compile the new model\n",
    "IV3_2.compile(optimizer=Adam(lr=0.00008), # was 0.0001\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath = 'inceptionv3.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = IV3_2.fit(x_train, Y_train, \n",
    "                 batch_size=32, \n",
    "                 epochs=100, \n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint],\n",
    "                 validation_data = (x_test, Y_test),\n",
    "                 shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ResNet50(include_top=True, weights=None,\n",
    "                               input_tensor=None, input_shape=(256,256,3), pooling=None)\n",
    "\n",
    "res.load_weights('./weights/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "# define a new output layer to connect with the last fc layer\n",
    "x = res.layers[-2].output\n",
    "output_layer = Dense(2, activation='softmax', name='fc2')(x)\n",
    "\n",
    "# combine the original model with the new output layer\n",
    "res2 = Model(inputs=res.input, outputs=output_layer)\n",
    "\n",
    "# compile the new model\n",
    "res2.compile(optimizer=Adam(lr=0.00008),\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath = 'resnet50.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = res2.fit(x_train, Y_train, \n",
    "                 batch_size=32, \n",
    "                 epochs=100, \n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint],\n",
    "                 validation_data = (x_test , Y_test),\n",
    "                 shuffle =True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
